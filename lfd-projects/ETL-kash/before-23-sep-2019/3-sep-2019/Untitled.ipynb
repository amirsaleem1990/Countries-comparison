{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(\"location.txt\", \"r\") as file:\n",
    "    location = file.read().strip().splitlines()\n",
    "d = {\"TimeStamp\" : [],\n",
    "    \"latitude\" : [],\n",
    "    \"longitude\" : []}\n",
    "for a in location:\n",
    "    b = a.replace(\"[\", \"\").\\\n",
    "        replace(\"]\", \"\")\n",
    "    c = eval(b).split(\"=\")\n",
    "    d[\"TimeStamp\"].append(c[0].replace(\"{\", \"\"))\n",
    "    d[\"latitude\"].append(c[2].split(\",\")[0])\n",
    "    d[\"longitude\"].append(c[3].replace(\")\", \"\").replace(\"}\", \"\"))\n",
    "\n",
    "df_location = pd.DataFrame(d)\n",
    "df_location.TimeStamp = pd.to_datetime(df_location.TimeStamp, unit=\"ms\")\n",
    "df_location.to_csv(\"location.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:2531: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  dtype=dtype, method=method)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "os.chdir('/home/amir/github/LFD-projects/ETL-cash-egypt/3-sep-2019')\n",
    "file_name = \"Sample 1 - Sept 2.zip\"\n",
    "folder_name = file_name.replace(\".zip\", \"\")\n",
    "if not folder_name in os.listdir():\n",
    "    os.mkdir(folder_name)\n",
    "    with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
    "        zip_ref.extractall(folder_name)\n",
    "os.chdir(folder_name)\n",
    "\n",
    "\n",
    "# ext_storage_files.txt\n",
    "with open(\"ext_storage_files.txt\", \"r\") as file:\n",
    "    ext_storage_files = file.read()\n",
    "a = eval(ext_storage_files)[0]\n",
    "b = a.replace(\" \", \"\").\\\n",
    "    replace(\"{\", '{\"').\\\n",
    "    replace(\"=\", '\":\"').\\\n",
    "    replace(\",\", '\",\"').\\\n",
    "    replace(']\",', '\"],').\\\n",
    "    replace(':\"[', ':[\"').\\\n",
    "    replace('[\"]', \"[]\" ).\\\n",
    "    replace('[\"\"]', '[]')\n",
    "d = eval(b)\n",
    "df_ext_storage_files = pd.DataFrame()\n",
    "for i in d:\n",
    "    if len(d[i]) == 1:\n",
    "        df_ext_storage_files[i] = d[i]\n",
    "    else:\n",
    "        df_ext_storage_files[i] = ['|'.join(d[i])]\n",
    "\n",
    "\n",
    "# sms_sent_log.txt\n",
    "with open(\"sms_sent_log.txt\", \"r\") as file:\n",
    "    sms_sent_log = file.read()\n",
    "d = {\"count\" : [],\n",
    "     \"date\" : []}\n",
    "for l in eval(sms_sent_log):\n",
    "    a = l.replace(\" \", \"\").\\\n",
    "        replace(\",\", '\",\"').\\\n",
    "        replace(\"{\", '{\"').\\\n",
    "        replace(\"}\", '\"}').\\\n",
    "        replace(\"=\", '\":\"')\n",
    "    b = eval(a)\n",
    "    for i in d:\n",
    "        d[i].append(b[i])\n",
    "df_sms_sent_log = pd.DataFrame(d)[[\"date\", \"count\"]]\n",
    "\n",
    "\n",
    "# contacts_list.txt\n",
    "with open(\"contacts_list.txt\", \"r\") as file:\n",
    "    contacts_list = file.read()\n",
    "a = eval(contacts_list)\n",
    "dd = {\"displayName\" : [],\n",
    "     \"phone\" : []}\n",
    "for b in a:\n",
    "    c = b.replace(\" \", \"\").\\\n",
    "        replace(\"=\", '\":\"').\\\n",
    "        replace(\"{\", '{\"').\\\n",
    "        replace(\"}\", '\"}').\\\n",
    "        replace(\",\", '\",\"')\n",
    "    if \",\" in c[c.find(\"phone\")+8:]:\n",
    "        c = c.replace('phone\":\"', 'phone\":[\"').replace('\"}', '\"]}' )\n",
    "    d = eval(c)\n",
    "    dd[\"displayName\"].append(d[\"displayName\"])\n",
    "    dd[\"phone\"].append(d[\"phone\"])\n",
    "df_contacts_list = pd.DataFrame.from_dict(dd)\n",
    "df_contacts_list.phone = [\"{\" + \", \".join(i) + \"}\" if isinstance(i, list) else i for i in df_contacts_list.phone.to_list()]\n",
    "\n",
    "\n",
    "# sms_log.txt\n",
    "with open(\"sms_log.txt\", \"r\") as file:\n",
    "    sms_log = eval(file.readlines()[0])\n",
    "d = {\"Address\" : [],\n",
    "     \"Body\" : [],\n",
    "     \"Type\" : [],\n",
    "     \"sendDate\" : [],\n",
    "     \"senderName\" : []}\n",
    "\n",
    "for i in sms_log:\n",
    "    a = i.split(\"=\")\n",
    "    d[\"Address\"].append(' '.join(a[1].split(\", \")[:-1]))\n",
    "    d[\"Body\"].append(' '.join(a[2].split(\", \")[:-1]))\n",
    "    d[\"Type\"].append(' '.join(a[3].split(\", \")[:-1]))\n",
    "    d[\"sendDate\"].append(' '.join(a[4].split(\", \")[:-1]))\n",
    "    d[\"senderName\"].append(a[5].replace(\"}\", \"\"))\n",
    "df_sms_log = pd.DataFrame(d)\n",
    "# with open(\"sms_log.txt\", \"r\") as file:\n",
    "#     sms_log = eval(file.read())\n",
    "# d = {\"Address\" : [],\n",
    "#      \"Body\" : [],\n",
    "#      \"Type\" : [],\n",
    "#      \"sendDate\" : [],\n",
    "#      \"senderName\" : []}\n",
    "# for e, a in enumerate(sms_log):\n",
    "#     b = eval(\n",
    "#         a.replace(\"}\", '\"}').\\\n",
    "#         replace(\"{\", '{\"').\\\n",
    "#         replace(\" \", \"\").\\\n",
    "#         replace(\"=\", '\":\"').\\\n",
    "#         replace(\"\\r\", \"\").\\\n",
    "#         replace(\"\\n\", \"\").\\\n",
    "#         replace(',Type\":', '\",\"Type\":').\\\n",
    "#         replace(',senderName\":', '\",\"senderName\":').\\\n",
    "#         replace(',Body\"', '\",\"Body\"').\\\n",
    "#         replace(',sendDate\"', '\",\"sendDate\"')\n",
    "#         )\n",
    "#     for i in d:\n",
    "#         d[i].append(b[i]) \n",
    "# df_sms_log = pd.DataFrame(d)\n",
    "\n",
    "\n",
    "# phone_battery_level.txt\n",
    "with open(\"phone_battery_level.txt\", \"r\") as file:\n",
    "    phone_battery_level = file.read()    \n",
    "a = eval(phone_battery_level)[0]\n",
    "d = {\"battery_level\" :  a.split(\"=\")[-1].replace(\"}\", \"\")}\n",
    "S_phone_battery_level = pd.Series(d)\n",
    "\n",
    "\n",
    "# outgoing_call_log.txt\n",
    "with open(\"outgoing_call_log.txt\", \"r\") as file:\n",
    "    outgoing_call_log = file.read()\n",
    "d = {}\n",
    "for i in outgoing_call_log.split(\",\"):\n",
    "    b = i.replace(\"[\", \"\").\\\n",
    "    replace(\"{\", \"\").\\\n",
    "    replace(\"}\", \"\").\\\n",
    "    replace(\"]\", \"\").strip()\n",
    "    c = b.split(\"=\")\n",
    "    d[c[0]]= int(c[1])\n",
    "df_outgoing_call_log = pd.DataFrame(pd.Series(d), columns=[\"outgoing_call_log\"])\n",
    "df_outgoing_call_log = df_outgoing_call_log.reset_index()\n",
    "df_outgoing_call_log.columns = [\"Date\", \"Count\"]\n",
    "\n",
    "# ip_address.txt\n",
    "with open(\"ip_address.txt\", \"r\") as file:\n",
    "    ip_address = file.read()\n",
    "d = dict([eval(ip_address)[0].\\\n",
    "      replace(\"{\", \"\").\\\n",
    "      replace(\"}\", \"\").split(\"=\")])\n",
    "S_ip_address = pd.Series(d)\n",
    "\n",
    "\n",
    "# location.txt\n",
    "with open(\"location.txt\", \"r\") as file:\n",
    "    location = file.read().strip().splitlines()\n",
    "d = {\"TimeStamp\" : [],\n",
    "    \"latitude\" : [],\n",
    "    \"longitude\" : []}\n",
    "for a in location:\n",
    "    b = a.replace(\"[\", \"\").\\\n",
    "        replace(\"]\", \"\")\n",
    "    c = eval(b).split(\"=\")\n",
    "    d[\"TimeStamp\"].append(c[0].replace(\"{\", \"\"))\n",
    "    d[\"latitude\"].append(c[2].split(\",\")[0])\n",
    "    d[\"longitude\"].append(c[3].replace(\")\", \"\").replace(\"}\", \"\"))\n",
    "df_location = pd.DataFrame(d)\n",
    "\n",
    "\n",
    "# storage_size.txt\n",
    "with open(\"storage_size.txt\", \"r\") as file:\n",
    "    storage_size = file.read()\n",
    "S_storage_size = pd.Series({\"storage_size\" : storage_size})\n",
    "\n",
    "#******************************* from Here FARAZ work *******************************\n",
    "\n",
    "# accounts_list.txt\n",
    "with open(\"accounts_list.txt\",\"r\") as f:\n",
    "    x = f.readline()\n",
    "accounts = json.loads(x)\n",
    "key = list()\n",
    "sample = (accounts[0].strip('{}')).split(',')\n",
    "for s in sample:\n",
    "    key.append(s.split('=')[0])\n",
    "accounts_list = dict()\n",
    "name = list()\n",
    "domain_type = list()\n",
    "for account in accounts:\n",
    "    domains = (account.strip('{}')).split(',')\n",
    "    for domain in domains:\n",
    "        #print((domain.split('=')))\n",
    "        if(str.lower(domain.strip().split('=')[0])=='name'):\n",
    "            name.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='type'):\n",
    "            domain_type.append(domain.split('=')[1])\n",
    "value = [name, domain_type]\n",
    "accounts_list = dict(zip(key , value))\n",
    "df_accounts_list = pd.DataFrame(accounts_list)\n",
    "\n",
    "# app_install_log.txt\n",
    "with open(\"app_install_log.txt\",\"r\") as f:\n",
    "    x = f.readline()\n",
    "app_install_log = json.loads(x)\n",
    "key = list()\n",
    "sample = (app_install_log[0].strip('{}')).split(',')\n",
    "for s in sample:\n",
    "    key.append(s.split('=')[0])    \n",
    "app_list = dict()\n",
    "package = list()\n",
    "for a in app_install_log:\n",
    "    domains = (a.strip('{}')).split(',')\n",
    "    for domain in domains:\n",
    "        if(str.lower(domain.strip().split('=')[0])=='package'):\n",
    "            package.append(domain.split('=')[1])\n",
    "        else:\n",
    "            print('new field')\n",
    "value = [package]\n",
    "app_list = dict(zip(key , value))\n",
    "df_app_install_log = pd.DataFrame(app_list)\n",
    "\n",
    "\n",
    "# gallery_data.txt\n",
    "with open(\"gallery_data.txt\",\"r\") as f:\n",
    "    x = f.readline()\n",
    "gallery_data = json.loads(x)\n",
    "key = list()\n",
    "sample = (gallery_data[0].strip('{}')).split(',')\n",
    "for s in sample:\n",
    "    key.append(s.split('=')[0])    \n",
    "d = dict()\n",
    "title = list()\n",
    "timestamp = list()\n",
    "path = list()\n",
    "for a in gallery_data:\n",
    "    domains = (a.strip('{}')).split(',')\n",
    "    for domain in domains:\n",
    "        #print((domain.split('=')))\n",
    "        if(str.lower(domain.strip().split('=')[0])=='title'):\n",
    "            title.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='timestamp'):\n",
    "            timestamp.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='path'):\n",
    "            path.append(domain.split('=')[1])\n",
    "        else:\n",
    "            print('new field')            \n",
    "value = [title,timestamp,path]\n",
    "galary_data = dict(zip(key , value))\n",
    "df_galary_data = pd.DataFrame(galary_data)\n",
    "\n",
    "\n",
    "# call_log.txt\n",
    "with open(\"call_log.txt\",\"r\") as f:\n",
    "    x = f.readline()\n",
    "call_log = json.loads(x)\n",
    "key = list()\n",
    "sample = (call_log[0].strip('{}')).split(',')\n",
    "for s in sample:\n",
    "    key.append(s.split('=')[0])\n",
    "d = dict()\n",
    "number = list()\n",
    "Type = list()\n",
    "DateTime = list()\n",
    "Duration= list()\n",
    "for a in call_log:\n",
    "    domains = (a.strip('{}')).split(',')\n",
    "    for domain in domains:\n",
    "        #print((domain.split('=')))\n",
    "        if(str.lower(domain.strip().split('=')[0])=='number'):\n",
    "            number.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='type'):\n",
    "            Type.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='datetime'):\n",
    "            DateTime.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='duration'):\n",
    "            Duration.append(domain.split('=')[1])\n",
    "        else:\n",
    "            print('new field')\n",
    "value = [number,Type,DateTime,Duration]\n",
    "call_log = dict(zip(key , value))\n",
    "df_call_log = pd.DataFrame(call_log)\n",
    "\n",
    "\n",
    "# device_info.txt\n",
    "with open(\"device_info.txt\",\"r\") as f:\n",
    "    x = f.readline()\n",
    "device_info = json.loads(x)\n",
    "key = list()\n",
    "sample = (device_info[0].strip('{}')).split(',')\n",
    "for s in sample:\n",
    "    key.append(s.split('=')[0])\n",
    "d = dict()\n",
    "model = list()\n",
    "manufacturer = list()\n",
    "brand = list()\n",
    "deviceSoftware= list()\n",
    "networkOperator = list()\n",
    "ram = list()\n",
    "for a in device_info:\n",
    "    domains = (a.strip('{}')).split(',')\n",
    "    for domain in domains:\n",
    "        if(str.lower(domain.strip().split('=')[0])=='model'):\n",
    "            model.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='manufacturer'):\n",
    "            manufacturer.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='brand'):\n",
    "            brand.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='devicesoftware'):\n",
    "            deviceSoftware.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='networkoperator'):\n",
    "            networkOperator.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='ram'):\n",
    "            ram.append(domain.split('=')[1])            \n",
    "value = [model,manufacturer,brand,deviceSoftware,networkOperator,ram]\n",
    "value = [i[0] for i in value]\n",
    "device_info = dict(zip(key , value))\n",
    "S_device_info = pd.Series(device_info)\n",
    "\n",
    "# filter_app_log.txt\n",
    "with open(\"filter_app_log.txt\",\"r\") as f:\n",
    "    x = f.readline()\n",
    "filter_app_log = json.loads(x)\n",
    "key = list()\n",
    "sample = (filter_app_log[0].strip('{}')).split(', ')\n",
    "for s in sample:\n",
    "    key.append(s.split('=')[0])   \n",
    "d = dict()\n",
    "social = list()\n",
    "dangerous = list()\n",
    "darkweb = list()\n",
    "wallet= list()\n",
    "banking = list()\n",
    "lending = list()\n",
    "rosca = list()\n",
    "for a in filter_app_log:\n",
    "    domains = (a.strip('{}')).split(', ')\n",
    "    for domain in domains:\n",
    "        if(str.lower(domain.strip().split('=')[0])=='social'):\n",
    "            social.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='dangerous'):\n",
    "            dangerous.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='darkweb'):\n",
    "            darkweb.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='wallet'):\n",
    "            wallet.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='banking'):\n",
    "            banking.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='lending'):\n",
    "            lending.append(domain.split('=')[1])\n",
    "        elif(str.lower(domain.strip().split('=')[0])=='rosca'):\n",
    "            rosca.append(domain.split('=')[1])\n",
    "value = [social,dangerous,darkweb,wallet,banking,lending,rosca]\n",
    "filter_app_log = dict(zip(key , value))\n",
    "df_filter_app_log = pd.DataFrame(filter_app_log)\n",
    "\n",
    "\n",
    "# calendar_events.txt\n",
    "with open(\"calendar_events.txt\",\"r\") as f:\n",
    "    x = f.readline()\n",
    "if bool(eval(x)):\n",
    "    calendar_events = json.loads(x)\n",
    "    key = list()\n",
    "    sample = (calendar_events[0].strip('{}')).split(', ')\n",
    "    for s in sample:\n",
    "        key.append(s.split('=')[0])\n",
    "    d = dict()\n",
    "    title = list()\n",
    "    description = list()\n",
    "    allowReminders = list()\n",
    "    dTStart= list()\n",
    "    dTEnd = list()\n",
    "    allDay = list()\n",
    "    for a in calendar_events:\n",
    "        domains = (a.strip('{}')).split(', ')\n",
    "        for domain in domains:\n",
    "            if(str.lower(domain.strip().split('=')[0])=='title'):\n",
    "                title.append(domain.split('=')[1])\n",
    "            elif(str.lower(domain.strip().split('=')[0])=='description'):\n",
    "                description.append(domain.split('=')[1])\n",
    "            elif(str.lower(domain.strip().split('=')[0])=='allowreminders'):\n",
    "                allowReminders.append(domain.split('=')[1])\n",
    "            elif(str.lower(domain.strip().split('=')[0])=='dtstart'):\n",
    "                dTStart.append(domain.split('=')[1])\n",
    "            elif(str.lower(domain.strip().split('=')[0])=='dtend'):\n",
    "                dTEnd.append(domain.split('=')[1])\n",
    "            elif(str.lower(domain.strip().split('=')[0])=='allday'):\n",
    "                allDay.append(domain.split('=')[1])\n",
    "    value = [title,description,allowReminders,dTStart,dTEnd,allDay]\n",
    "    calendar_events = dict(zip(key , value))\n",
    "    df_calendar_events = pd.DataFrame(calendar_events)\n",
    "else:\n",
    "    df_calendar_events = pd.DataFrame()\n",
    "\n",
    "conn = sqlite3.connect('/home/amir/ETL.db')  \n",
    "c = conn.cursor()\n",
    "# if_exists='append'\n",
    "for table_name, i in zip([\"sms_log\",\"outgoing_call_log\",\"accounts_list\",\"filter_app_log\",\"calendar_events\",\n",
    "    \"location\",\"galary_data\",\"call_log\",\"contacts_list\",\"app_install_log\",\"ext_storage_files\",\"sms_sent_log\"], \n",
    "    [df_sms_log, df_outgoing_call_log, df_accounts_list, df_filter_app_log,df_calendar_events,df_location,\n",
    "    df_galary_data,df_call_log,df_contacts_list,df_app_install_log,df_ext_storage_files,df_sms_sent_log]):\n",
    "    if len(i) > 0:\n",
    "        df_temp = pd.read_sql_query(\"SELECT * FROM \" + table_name, conn)\n",
    "        # srif wo records jo <i> me hen lekin <df_temp> me nahi\n",
    "        only_new = i[~i.isin(df_temp.to_dict('l')).all(1)]\n",
    "        i['ID'] = [\"ID Sep 2\" for z in range(len(i))]\n",
    "        i = i[[\"ID\"] + i.columns[:-1].to_list()]\n",
    "        i.to_sql(table_name, conn, index=False, if_exists='append')\n",
    "        \n",
    "if len(S_phone_battery_level) == 0:\n",
    "    S_phone_battery_level = pd.Series({\"battery_level\" : \"NA\"})\n",
    "\n",
    "if len(S_ip_address) == 0:\n",
    "    S_ip_address = pd.Series({\"ipaddress\" : \"NA\"})\n",
    "    \n",
    "if len(S_device_info) == 0:\n",
    "    S_device_info = pd.Series({' brand': 'NA',\n",
    "                             ' deviceSoftware': 'NA',\n",
    "                             ' manufacturer': 'NA',\n",
    "                             ' networkOperator': 'NA',\n",
    "                             ' ram': 'NA',\n",
    "                             'model': 'NA'})\n",
    "    \n",
    "if len(S_storage_size) == 0:\n",
    "    S_storage_size = pd.Series({'storage_size': 'NA'})\n",
    "    \n",
    "conn = sqlite3.connect('/home/amir/Master.db')  \n",
    "c = conn.cursor()\n",
    "\n",
    "df_master = pd.DataFrame(pd.concat([S_phone_battery_level, S_ip_address, S_device_info, S_storage_size])).T\n",
    "df_sql = pd.read_sql_query(\"SELECT * FROM Master\", conn)\n",
    "\n",
    "dm = df_master[[i for i in df_master.columns if i != \"ID\"]]\n",
    "ds = df_sql[[i for i in df_sql.columns if i != \"ID\"]]\n",
    "\n",
    "if not pd.merge(dm,ds).equals(dm):\n",
    "    dm[\"ID\"] = [\"ID Sep 2\"]\n",
    "    dm.to_sql('Master', conn, index=False, if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
